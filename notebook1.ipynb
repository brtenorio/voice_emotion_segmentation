{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import librosa\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.15.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "\n",
    "from keras.models import Model, load_model\n",
    "from keras.layers import GlobalAveragePooling2D, Dense, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Sophia', 'Ava', 'Olivia', 'Emma']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def unique_names(names1, names2):\n",
    "    return list(set(names1 + names2))\n",
    "\n",
    "unique_names(['Ava', 'Emma', 'Olivia'], ['Olivia', 'Sophia', 'Emma'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solution to the Sentiment Analysis Classifier Problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Description:\n",
    "\n",
    "You are given a dataset of movie reviews and their corresponding sentiment labels (positive or negative). Your task is to implement a simple sentiment analysis classifier using Python. You should use a basic machine learning model (like Logistic Regression) and preprocess the text data using Natural Language Processing (NLP) techniques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews = [\n",
    "    \"I loved this movie, it was fantastic!\",\n",
    "    \"Absolutely terrible movie, would not recommend.\",\n",
    "    \"The plot was decent, but the acting was poor.\",\n",
    "    \"An outstanding experience, truly a masterpiece!\",\n",
    "    \"This was the worst film I have ever seen.\"\n",
    "]\n",
    "\n",
    "labels = [1, 0, 0, 1, 0]\n",
    "\n",
    "test_reviews = [\n",
    "    \"I enjoyed watching this movie.\",\n",
    "    \"The movie was a waste of time.\"\n",
    "]\n",
    "\n",
    "# Expected Output: Accuracy score on the test dataset (e.g., 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 22) (1, 22)\n",
      "(2, 22)\n",
      "['acting' 'an' 'but' 'decent' 'ever' 'experience' 'fantastic' 'film'\n",
      " 'have' 'it' 'loved' 'masterpiece' 'movie' 'outstanding' 'plot' 'poor'\n",
      " 'seen' 'the' 'this' 'truly' 'was' 'worst'] 22\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Create a TfidfVectorizer\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "\n",
    "# Split the data into X_train and X_test\n",
    "X_train, X_val, y_train, y_val = train_test_split(reviews, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Fit and transform the training data\n",
    "X_tfidf_train = tfidf_vectorizer.fit_transform(X_train)\n",
    "\n",
    "# Transform the validation data\n",
    "X_tfidf_val = tfidf_vectorizer.transform(X_val)\n",
    "\n",
    "print(X_tfidf_train.shape, X_tfidf_val.shape)\n",
    "\n",
    "# Transform the test set\n",
    "X_tfidf_test = tfidf_vectorizer.transform(test_reviews)\n",
    "print(X_tfidf_test.shape)\n",
    "\n",
    "# Print the features\n",
    "print(tfidf_vectorizer.get_feature_names_out(), len(tfidf_vectorizer.get_feature_names_out()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valuation: [1] y_val:  [0]\n",
      "[ True  True]\n",
      "accuracy:  1.0\n"
     ]
    }
   ],
   "source": [
    "# Logistic regression on the training data\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Create a Logistic Regression model\n",
    "lr = LogisticRegression()\n",
    "\n",
    "# Fit the model\n",
    "lr.fit(X_tfidf_train, y_train) \n",
    "\n",
    "# Make predictions\n",
    "val = lr.predict(X_tfidf_val)\n",
    "print(\"valuation:\", val, \"y_val: \" , y_val)\n",
    "\n",
    "preds = lr.predict(X_tfidf_test)\n",
    "\n",
    "print(preds == [1, 0])\n",
    "\n",
    "# Calculate the accuracy\n",
    "accuracy = (preds == [1, 0]).mean()\n",
    "print(\"accuracy: \",accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem: Text Classification with Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Description:\n",
    "\n",
    "You are given a dataset of SMS messages labeled as either \"spam\" or \"ham\" (non-spam). Your task is to implement a text classification system using Python to identify whether a given SMS message is spam or not. You will use the Naive Bayes classifier, which is commonly used for text classification tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    \"Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005.\",\n",
    "    \"Nah I don't think he goes to usf, he lives around here though.\",\n",
    "    \"FreeMsg Hey there darling it's been 3 weeks now and no word back!\",\n",
    "    \"Even my brother is not like to speak with me. They treat me like aids patent.\",\n",
    "    \"WINNER!! As a valued network customer you have been selected to receive a £900 prize reward!\"\n",
    "]\n",
    "\n",
    "labels = [1, 0, 1, 0, 1]\n",
    "\n",
    "test_messages = [\n",
    "    \"Congratulations, you have won a $1000 Walmart gift card. Go to http://bit.ly/123456 to claim now.\",\n",
    "    \"I'll text you when I'm done. See you later.\"\n",
    "]\n",
    "\n",
    "# Expected Output: Accuracy score on the test dataset (e.g., 0.5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 61)\n",
      "(2, 61)\n",
      "['2005' '21st' '900' 'aids' 'and' 'around' 'as' 'back' 'been' 'brother'\n",
      " 'comp' 'cup' 'customer' 'darling' 'don' 'entry' 'even' 'fa' 'final'\n",
      " 'free' 'freemsg' 'goes' 'have' 'he' 'here' 'hey' 'in' 'is' 'it' 'like'\n",
      " 'lives' 'may' 'me' 'my' 'nah' 'network' 'no' 'not' 'now' 'patent' 'prize'\n",
      " 'receive' 'reward' 'selected' 'speak' 'there' 'they' 'think' 'though'\n",
      " 'tkts' 'to' 'treat' 'usf' 'valued' 'weeks' 'win' 'winner' 'with' 'wkly'\n",
      " 'word' 'you'] 61\n"
     ]
    }
   ],
   "source": [
    "# Create a TfidfVectorizer\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "\n",
    "# Split the data into X_train and X_test\n",
    "# X_train, X_val, y_train, y_val = train_test_split(messages, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Fit and transform the training data\n",
    "X_tfidf_train = tfidf_vectorizer.fit_transform(messages)\n",
    "\n",
    "# Transform the validation data\n",
    "# X_tfidf_val = tfidf_vectorizer.transform(X_val)\n",
    "\n",
    "print(X_tfidf_train.shape)\n",
    "\n",
    "# Transform the test set\n",
    "X_tfidf_test = tfidf_vectorizer.transform(test_messages)\n",
    "print(X_tfidf_test.shape)\n",
    "\n",
    "# Print the features\n",
    "print(tfidf_vectorizer.get_feature_names_out(), len(tfidf_vectorizer.get_feature_names_out()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1] ; [ True False]\n",
      "accuracy:  0.5\n"
     ]
    }
   ],
   "source": [
    "# Logistic regression on the training data\n",
    "\n",
    "lr = LogisticRegression()\n",
    "\n",
    "# Fit the model\n",
    "lr.fit(X_tfidf_train, labels)\n",
    "\n",
    "# Make predictions\n",
    "\n",
    "preds = lr.predict(X_tfidf_test)\n",
    "\n",
    "print(preds, \";\", preds == [1, 0])\n",
    "\n",
    "# Calculate the accuracy\n",
    "accuracy = (preds == [1, 0]).mean()\n",
    "print(\"accuracy: \",accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### another approach using CountVectorizer and NB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005.'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(string.punctuation)\n",
    "messages[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''.join([char for char in messages[0] if char not in string.punctuation])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['free entry in 2 a wkly comp to win fa cup final tkts 21st may 2005', 'nah i dont think he goes to usf he lives around here though', 'freemsg hey there darling its been 3 weeks now and no word back', 'even my brother is not like to speak with me they treat me like aids patent', 'winner as a valued network customer you have been selected to receive a £900 prize reward']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import string\n",
    "\n",
    "def clean_text(text):\n",
    "    \"\"\" \n",
    "    Converts text to lowercase, removes punctuation and digits, and replaces\n",
    "    consecutive whitespaces by a single space.\n",
    "    \"\"\"\n",
    "    text = text.lower()  # Convert text to lowercase\n",
    "    text = ''.join([char for char in text if char not in string.punctuation])  # Remove punctuation\n",
    "    return text\n",
    "\n",
    "# Clean the training messages\n",
    "cleaned_messages = [clean_text(msg) for msg in messages]\n",
    "print(cleaned_messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 61) (2, 61)\n",
      "['2005' '21st' '900' 'aids' 'and' 'around' 'as' 'back' 'been' 'brother'\n",
      " 'comp' 'cup' 'customer' 'darling' 'dont' 'entry' 'even' 'fa' 'final'\n",
      " 'free' 'freemsg' 'goes' 'have' 'he' 'here' 'hey' 'in' 'is' 'its' 'like'\n",
      " 'lives' 'may' 'me' 'my' 'nah' 'network' 'no' 'not' 'now' 'patent' 'prize'\n",
      " 'receive' 'reward' 'selected' 'speak' 'there' 'they' 'think' 'though'\n",
      " 'tkts' 'to' 'treat' 'usf' 'valued' 'weeks' 'win' 'winner' 'with' 'wkly'\n",
      " 'word' 'you'] 61\n",
      "[[1 1 0 0 0 0 0 0 0 0 1 1 0 0 0 1 0 1 1 1 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 1 0 0 1 0 0]\n",
      " [0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 2 1 0 0 0 0 0 1 0 0 0 1 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 1 1 0 1 0 1 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 1 0 0 1 1 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0\n",
      "  1 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0]\n",
      " [0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 2 0 0 2 1 0 0\n",
      "  0 1 0 1 0 0 0 0 1 0 1 0 0 0 1 1 0 0 0 0 0 1 0 0 0]\n",
      " [0 0 1 0 0 0 1 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1\n",
      "  0 0 0 0 1 1 1 1 0 0 0 0 0 0 1 0 0 1 0 0 1 0 0 0 1]]\n"
     ]
    }
   ],
   "source": [
    "# instantiate count vectorizer\n",
    "count_vectorizer = CountVectorizer()\n",
    "\n",
    "# Fit and transform the training data\n",
    "\n",
    "X_count_train = count_vectorizer.fit_transform(cleaned_messages)\n",
    "\n",
    "# Transform the test set\n",
    "cleaned_test_messages = [clean_text(msg) for msg in test_messages]\n",
    "X_count_test = count_vectorizer.transform(cleaned_test_messages)\n",
    "\n",
    "print(X_count_train.shape, X_count_test.shape)\n",
    "print(count_vectorizer.get_feature_names_out(), len(count_vectorizer.get_feature_names_out()))\n",
    "print(X_count_train.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1] ; [ True False]\n",
      "accuracy:  0.5\n"
     ]
    }
   ],
   "source": [
    "# Create a MultinomialNB model\n",
    "nb = MultinomialNB()\n",
    "\n",
    "# Fit the model\n",
    "nb.fit(X_count_train, labels)\n",
    "\n",
    "# Make predictions\n",
    "preds = nb.predict(X_count_test)\n",
    "\n",
    "print(preds, \";\", preds == [1, 0])\n",
    "\n",
    "# Calculate the accuracy\n",
    "accuracy = (preds == [1, 0]).mean()\n",
    "print(\"accuracy: \",accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Named Entity Recognition (NER) with Conditional Random Fields (CRF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Description:\n",
    "\n",
    "You are given a dataset consisting of sentences, where each word in a sentence is labeled with its corresponding named entity. The named entities are categorized into three types: PERSON, ORG (organization), LOC (location), or O (other, meaning no named entity). Your task is to implement a Named Entity Recognition (NER) system using Python that labels the entities in sentences using Conditional Random Fields (CRF)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn_crfsuite\n",
    "from sklearn_crfsuite import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn_crfsuite.metrics import flat_classification_report\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = [\n",
    "    [(\"John\", \"PERSON\"), (\"works\", \"O\"), (\"at\", \"O\"), (\"Acme\", \"ORG\"), (\".\", \"O\")],\n",
    "    [(\"Paris\", \"LOC\"), (\"is\", \"O\"), (\"beautiful\", \"O\"), (\"in\", \"O\"), (\"spring\", \"O\")],\n",
    "    [(\"Mary\", \"PERSON\"), (\"lives\", \"O\"), (\"in\", \"O\"), (\"New\", \"LOC\"), (\"York\", \"LOC\")],\n",
    "]\n",
    "\n",
    "test_sentences = [\n",
    "    [(\"Alice\", \"O\"), (\"is\", \"O\"), (\"from\", \"O\"), (\"London\", \"LOC\")],\n",
    "    [(\"Google\", \"ORG\"), (\"was\", \"O\"), (\"founded\", \"O\"), (\"by\", \"O\"), (\"Larry\", \"PERSON\"), (\"and\", \"O\"), (\"Sergey\", \"PERSON\")],\n",
    "]\n",
    "\n",
    "# Expected Output: Precision, recall, and F1-score (e.g., {\"precision\": 0.85, \"recall\": 0.80, \"f1\": 0.82})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word2features(sent, i):\n",
    "    word = sent[i][0]\n",
    "    features = {\n",
    "        'word': word,\n",
    "        'lowercase': word.lower(),\n",
    "        'is_capitalized': word[0].isupper(),\n",
    "        'is_digit': word.isdigit(),\n",
    "        'prefix-1': word[:1],\n",
    "        'suffix-1': word[-1:],\n",
    "        'prefix-2': word[:2],\n",
    "        'suffix-2': word[-2:]\n",
    "    }\n",
    "    \n",
    "    if i > 0:\n",
    "        word1 = sent[i-1][0]\n",
    "        features.update({\n",
    "            '-1:word': word1,\n",
    "            '-1:is_capitalized': word1[0].isupper(),\n",
    "            '-1:lowercase': word1.lower()\n",
    "        })\n",
    "    else:\n",
    "        features['BOS'] = True  # Beginning of a sentence\n",
    "\n",
    "    if i < len(sent)-1:\n",
    "        word1 = sent[i+1][0]\n",
    "        features.update({\n",
    "            '+1:word': word1,\n",
    "            '+1:is_capitalized': word1[0].isupper(),\n",
    "            '+1:lowercase': word1.lower()\n",
    "        })\n",
    "    else:\n",
    "        features['EOS'] = True  # End of a sentence\n",
    "\n",
    "    return features\n",
    "\n",
    "def sentence2features(sent):\n",
    "    return [word2features(sent, i) for i in range(len(sent))]\n",
    "\n",
    "def sentence2labels(sent):\n",
    "    return [label for token, label in sent]\n",
    "\n",
    "def sentence2tokens(sent):\n",
    "    return [token for token, label in sent]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = [sentence2features(s) for s in sentences]\n",
    "y_train = [sentence2labels(s) for s in sentences]\n",
    "\n",
    "X_test = [sentence2features(s) for s in test_sentences]\n",
    "y_test = [sentence2labels(s) for s in test_sentences]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[{'word': 'John',\n",
       "   'lowercase': 'john',\n",
       "   'is_capitalized': True,\n",
       "   'is_digit': False,\n",
       "   'prefix-1': 'J',\n",
       "   'suffix-1': 'n',\n",
       "   'prefix-2': 'Jo',\n",
       "   'suffix-2': 'hn',\n",
       "   'BOS': True,\n",
       "   '+1:word': 'works',\n",
       "   '+1:is_capitalized': False,\n",
       "   '+1:lowercase': 'works'},\n",
       "  {'word': 'works',\n",
       "   'lowercase': 'works',\n",
       "   'is_capitalized': False,\n",
       "   'is_digit': False,\n",
       "   'prefix-1': 'w',\n",
       "   'suffix-1': 's',\n",
       "   'prefix-2': 'wo',\n",
       "   'suffix-2': 'ks',\n",
       "   '-1:word': 'John',\n",
       "   '-1:is_capitalized': True,\n",
       "   '-1:lowercase': 'john',\n",
       "   '+1:word': 'at',\n",
       "   '+1:is_capitalized': False,\n",
       "   '+1:lowercase': 'at'},\n",
       "  {'word': 'at',\n",
       "   'lowercase': 'at',\n",
       "   'is_capitalized': False,\n",
       "   'is_digit': False,\n",
       "   'prefix-1': 'a',\n",
       "   'suffix-1': 't',\n",
       "   'prefix-2': 'at',\n",
       "   'suffix-2': 'at',\n",
       "   '-1:word': 'works',\n",
       "   '-1:is_capitalized': False,\n",
       "   '-1:lowercase': 'works',\n",
       "   '+1:word': 'Acme',\n",
       "   '+1:is_capitalized': True,\n",
       "   '+1:lowercase': 'acme'},\n",
       "  {'word': 'Acme',\n",
       "   'lowercase': 'acme',\n",
       "   'is_capitalized': True,\n",
       "   'is_digit': False,\n",
       "   'prefix-1': 'A',\n",
       "   'suffix-1': 'e',\n",
       "   'prefix-2': 'Ac',\n",
       "   'suffix-2': 'me',\n",
       "   '-1:word': 'at',\n",
       "   '-1:is_capitalized': False,\n",
       "   '-1:lowercase': 'at',\n",
       "   '+1:word': '.',\n",
       "   '+1:is_capitalized': False,\n",
       "   '+1:lowercase': '.'},\n",
       "  {'word': '.',\n",
       "   'lowercase': '.',\n",
       "   'is_capitalized': False,\n",
       "   'is_digit': False,\n",
       "   'prefix-1': '.',\n",
       "   'suffix-1': '.',\n",
       "   'prefix-2': '.',\n",
       "   'suffix-2': '.',\n",
       "   '-1:word': 'Acme',\n",
       "   '-1:is_capitalized': True,\n",
       "   '-1:lowercase': 'acme',\n",
       "   'EOS': True}],\n",
       " [{'word': 'Paris',\n",
       "   'lowercase': 'paris',\n",
       "   'is_capitalized': True,\n",
       "   'is_digit': False,\n",
       "   'prefix-1': 'P',\n",
       "   'suffix-1': 's',\n",
       "   'prefix-2': 'Pa',\n",
       "   'suffix-2': 'is',\n",
       "   'BOS': True,\n",
       "   '+1:word': 'is',\n",
       "   '+1:is_capitalized': False,\n",
       "   '+1:lowercase': 'is'},\n",
       "  {'word': 'is',\n",
       "   'lowercase': 'is',\n",
       "   'is_capitalized': False,\n",
       "   'is_digit': False,\n",
       "   'prefix-1': 'i',\n",
       "   'suffix-1': 's',\n",
       "   'prefix-2': 'is',\n",
       "   'suffix-2': 'is',\n",
       "   '-1:word': 'Paris',\n",
       "   '-1:is_capitalized': True,\n",
       "   '-1:lowercase': 'paris',\n",
       "   '+1:word': 'beautiful',\n",
       "   '+1:is_capitalized': False,\n",
       "   '+1:lowercase': 'beautiful'},\n",
       "  {'word': 'beautiful',\n",
       "   'lowercase': 'beautiful',\n",
       "   'is_capitalized': False,\n",
       "   'is_digit': False,\n",
       "   'prefix-1': 'b',\n",
       "   'suffix-1': 'l',\n",
       "   'prefix-2': 'be',\n",
       "   'suffix-2': 'ul',\n",
       "   '-1:word': 'is',\n",
       "   '-1:is_capitalized': False,\n",
       "   '-1:lowercase': 'is',\n",
       "   '+1:word': 'in',\n",
       "   '+1:is_capitalized': False,\n",
       "   '+1:lowercase': 'in'},\n",
       "  {'word': 'in',\n",
       "   'lowercase': 'in',\n",
       "   'is_capitalized': False,\n",
       "   'is_digit': False,\n",
       "   'prefix-1': 'i',\n",
       "   'suffix-1': 'n',\n",
       "   'prefix-2': 'in',\n",
       "   'suffix-2': 'in',\n",
       "   '-1:word': 'beautiful',\n",
       "   '-1:is_capitalized': False,\n",
       "   '-1:lowercase': 'beautiful',\n",
       "   '+1:word': 'spring',\n",
       "   '+1:is_capitalized': False,\n",
       "   '+1:lowercase': 'spring'},\n",
       "  {'word': 'spring',\n",
       "   'lowercase': 'spring',\n",
       "   'is_capitalized': False,\n",
       "   'is_digit': False,\n",
       "   'prefix-1': 's',\n",
       "   'suffix-1': 'g',\n",
       "   'prefix-2': 'sp',\n",
       "   'suffix-2': 'ng',\n",
       "   '-1:word': 'in',\n",
       "   '-1:is_capitalized': False,\n",
       "   '-1:lowercase': 'in',\n",
       "   'EOS': True}],\n",
       " [{'word': 'Mary',\n",
       "   'lowercase': 'mary',\n",
       "   'is_capitalized': True,\n",
       "   'is_digit': False,\n",
       "   'prefix-1': 'M',\n",
       "   'suffix-1': 'y',\n",
       "   'prefix-2': 'Ma',\n",
       "   'suffix-2': 'ry',\n",
       "   'BOS': True,\n",
       "   '+1:word': 'lives',\n",
       "   '+1:is_capitalized': False,\n",
       "   '+1:lowercase': 'lives'},\n",
       "  {'word': 'lives',\n",
       "   'lowercase': 'lives',\n",
       "   'is_capitalized': False,\n",
       "   'is_digit': False,\n",
       "   'prefix-1': 'l',\n",
       "   'suffix-1': 's',\n",
       "   'prefix-2': 'li',\n",
       "   'suffix-2': 'es',\n",
       "   '-1:word': 'Mary',\n",
       "   '-1:is_capitalized': True,\n",
       "   '-1:lowercase': 'mary',\n",
       "   '+1:word': 'in',\n",
       "   '+1:is_capitalized': False,\n",
       "   '+1:lowercase': 'in'},\n",
       "  {'word': 'in',\n",
       "   'lowercase': 'in',\n",
       "   'is_capitalized': False,\n",
       "   'is_digit': False,\n",
       "   'prefix-1': 'i',\n",
       "   'suffix-1': 'n',\n",
       "   'prefix-2': 'in',\n",
       "   'suffix-2': 'in',\n",
       "   '-1:word': 'lives',\n",
       "   '-1:is_capitalized': False,\n",
       "   '-1:lowercase': 'lives',\n",
       "   '+1:word': 'New',\n",
       "   '+1:is_capitalized': True,\n",
       "   '+1:lowercase': 'new'},\n",
       "  {'word': 'New',\n",
       "   'lowercase': 'new',\n",
       "   'is_capitalized': True,\n",
       "   'is_digit': False,\n",
       "   'prefix-1': 'N',\n",
       "   'suffix-1': 'w',\n",
       "   'prefix-2': 'Ne',\n",
       "   'suffix-2': 'ew',\n",
       "   '-1:word': 'in',\n",
       "   '-1:is_capitalized': False,\n",
       "   '-1:lowercase': 'in',\n",
       "   '+1:word': 'York',\n",
       "   '+1:is_capitalized': True,\n",
       "   '+1:lowercase': 'york'},\n",
       "  {'word': 'York',\n",
       "   'lowercase': 'york',\n",
       "   'is_capitalized': True,\n",
       "   'is_digit': False,\n",
       "   'prefix-1': 'Y',\n",
       "   'suffix-1': 'k',\n",
       "   'prefix-2': 'Yo',\n",
       "   'suffix-2': 'rk',\n",
       "   '-1:word': 'New',\n",
       "   '-1:is_capitalized': True,\n",
       "   '-1:lowercase': 'new',\n",
       "   'EOS': True}]]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['PERSON', 'O', 'O', 'ORG', 'O'],\n",
       " ['LOC', 'O', 'O', 'O', 'O'],\n",
       " ['PERSON', 'O', 'O', 'LOC', 'LOC']]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>CRF(algorithm=&#x27;lbfgs&#x27;, all_possible_transitions=False, c1=0.1, c2=0.1,\n",
       "    max_iterations=100)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;CRF<span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>CRF(algorithm=&#x27;lbfgs&#x27;, all_possible_transitions=False, c1=0.1, c2=0.1,\n",
       "    max_iterations=100)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "CRF(algorithm='lbfgs', all_possible_transitions=False, c1=0.1, c2=0.1,\n",
       "    max_iterations=100)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crf = sklearn_crfsuite.CRF(\n",
    "    algorithm='lbfgs',\n",
    "    c1=0.1,\n",
    "    c2=0.1,\n",
    "    max_iterations=100,\n",
    "    all_possible_transitions=False\n",
    ")\n",
    "\n",
    "crf.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      PERSON      0.000     0.000     0.000         2\n",
      "         ORG      0.000     0.000     0.000         1\n",
      "         LOC      0.333     1.000     0.500         1\n",
      "           O      0.857     0.857     0.857         7\n",
      "\n",
      "    accuracy                          0.636        11\n",
      "   macro avg      0.298     0.464     0.339        11\n",
      "weighted avg      0.576     0.636     0.591        11\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/brncat/Downloads/AltaVerde/GitHub/voice_emotion_segmentation/.venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/brncat/Downloads/AltaVerde/GitHub/voice_emotion_segmentation/.venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/brncat/Downloads/AltaVerde/GitHub/voice_emotion_segmentation/.venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "y_pred = crf.predict(X_test)\n",
    "\n",
    "print(flat_classification_report(\n",
    "    y_test, y_pred, labels=['PERSON', 'ORG', 'LOC', 'O'], digits=3\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "210.24073823727426\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.stats as st\n",
    "\n",
    "def distribution_fitting(distribution_code, investments):\n",
    "    \"\"\"\n",
    "    :param distribution_code (string): 'norm', 'cauchy', or 'expon'.\n",
    "    :param investments: (list) The size of each investment received.\n",
    "    :returns: (float) Akaike information criterion of the distribution for the dataset.\n",
    "    \"\"\"\n",
    "    # Convert investments to a numpy array for easier manipulation\n",
    "    investments = np.array(investments)\n",
    "    \n",
    "    # Fit the distribution to the data\n",
    "    if distribution_code == 'norm':\n",
    "        params = st.norm.fit(investments)\n",
    "        log_likelihood = np.sum(st.norm.logpdf(investments, *params))\n",
    "        k = 2  # mean and standard deviation\n",
    "    elif distribution_code == 'cauchy':\n",
    "        params = st.cauchy.fit(investments)\n",
    "        log_likelihood = np.sum(st.cauchy.logpdf(investments, *params))\n",
    "        k = 2  # location and scale\n",
    "    elif distribution_code == 'expon':\n",
    "        params = st.expon.fit(investments)\n",
    "        log_likelihood = np.sum(st.expon.logpdf(investments, *params))\n",
    "        k = 2  # location and scale\n",
    "    else:\n",
    "        raise ValueError(\"Invalid distribution code. Use 'norm', 'cauchy', or 'expon'.\")\n",
    "\n",
    "    # Calculate AIC\n",
    "    aic = 2 * k - 2 * log_likelihood\n",
    "    \n",
    "    return aic\n",
    "\n",
    "# Test the function\n",
    "investments = [\n",
    "    11624, 9388, 9471, 8927,\n",
    "    10865, 7698, 11744, 9238,\n",
    "    10319, 9750, 11462, 7939\n",
    "]\n",
    "print(distribution_fitting('norm', investments))  # Expected output ~210.24074"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
